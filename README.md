# When Can You Trust Your Explanations? A Robustness Analysis On Feature Importances

This repository contains the code used for the paper "When can you trust your explanations? A robustness analysis on feature importances" (Vascotto, Rodriguez, Bonaita, Bortolussi), submitted at the 3rd World Conference on eXplainable Artificial Intelligence.
